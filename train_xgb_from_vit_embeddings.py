"""
ViTì—ì„œ ì¶”ì¶œí•œ CLS í† í° ì„ë² ë”©ì„ XGBoostë¡œ í•™ìŠµí•˜ëŠ” ëª¨ë“ˆ
"""

import pandas as pd
import numpy as np
import os
import json
from pathlib import Path
from typing import List, Dict, Any, Tuple

import xgboost as xgb
from sklearn.model_selection import KFold, GroupKFold
from sklearn.metrics import mean_squared_error, r2_score
import joblib

def load_embeddings(parquet_path: str) -> Tuple[pd.DataFrame, List[str], List[str]]:
    """
    ViT ì„ë² ë”© parquet íŒŒì¼ì„ ë¡œë“œí•˜ê³  í”¼ì²˜/ë¼ë²¨ ì»¬ëŸ¼ì„ ë¶„ë¦¬
    """
    print(f"ğŸ“ ì„ë² ë”© íŒŒì¼ ë¡œë“œ: {parquet_path}")
    
    if not os.path.exists(parquet_path):
        raise FileNotFoundError(f"ì„ë² ë”© íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {parquet_path}")
    
    df = pd.read_parquet(parquet_path)
    print(f"   ë°ì´í„° í¬ê¸°: {df.shape}")
    
    # í”¼ì²˜ ì»¬ëŸ¼ (f0, f1, f2, ...)ê³¼ ë¼ë²¨ ì»¬ëŸ¼ (y_*) ë¶„ë¦¬
    feature_cols = [col for col in df.columns if col.startswith('f') and col[1:].isdigit()]
    label_cols = [col for col in df.columns if col.startswith('y_')]
    
    print(f"   í”¼ì²˜ ì°¨ì›: {len(feature_cols)}ê°œ")
    print(f"   ë¼ë²¨ ê°œìˆ˜: {len(label_cols)}ê°œ")
    print(f"   ë¼ë²¨ë“¤: {label_cols}")
    
    return df, feature_cols, label_cols

def train_xgboost_single_target(X: np.ndarray, y: np.ndarray, 
                               groups: np.ndarray = None,
                               xgb_params: Dict[str, Any] = None) -> Dict[str, Any]:
    """
    ë‹¨ì¼ íƒ€ê²Ÿì— ëŒ€í•´ XGBoost í•™ìŠµ (K-Fold CV)
    """
    if xgb_params is None:
        xgb_params = {
            'objective': 'reg:squarederror',
            'max_depth': 6,
            'learning_rate': 0.1,
            'subsample': 0.8,
            'colsample_bytree': 0.8,
            'random_state': 2025,
            'n_estimators': 100
        }
    
    # K-Fold ì„¤ì •
    if groups is not None:
        # ê·¸ë£¹ ìˆ˜ í™•ì¸
        unique_groups = len(np.unique(groups))
        n_splits = min(5, unique_groups)
        
        if unique_groups >= 2:
            # ê·¸ë£¹ ê¸°ë°˜ CV (ê°™ì€ ì´ë ¥ë²ˆí˜¸ëŠ” ê°™ì€ fold)
            kf = GroupKFold(n_splits=n_splits)
            splits = list(kf.split(X, y, groups))
            print(f"     GroupKFold ì‚¬ìš©: {n_splits}ê°œ fold, {unique_groups}ê°œ ê·¸ë£¹")
        else:
            # ê·¸ë£¹ì´ 1ê°œë¿ì´ë©´ ì¼ë°˜ K-Fold ì‚¬ìš©
            print(f"     ê·¸ë£¹ì´ {unique_groups}ê°œë¿ì´ë¯€ë¡œ ì¼ë°˜ K-Fold ì‚¬ìš©")
            kf = KFold(n_splits=5, shuffle=True, random_state=2025)
            splits = list(kf.split(X, y))
    else:
        # ì¼ë°˜ K-Fold
        kf = KFold(n_splits=5, shuffle=True, random_state=2025)
        splits = list(kf.split(X, y))
    
    cv_scores = []
    models = []
    
    for fold, (train_idx, val_idx) in enumerate(splits):
        X_train, X_val = X[train_idx], X[val_idx]
        y_train, y_val = y[train_idx], y[val_idx]
        
        # XGBoost í•™ìŠµ
        model = xgb.XGBRegressor(**xgb_params)
        model.fit(X_train, y_train, 
                 eval_set=[(X_val, y_val)],
                 verbose=False)
        
        # ì˜ˆì¸¡ ë° í‰ê°€
        y_pred = model.predict(X_val)
        rmse = np.sqrt(mean_squared_error(y_val, y_pred))
        r2 = r2_score(y_val, y_pred)
        
        cv_scores.append({'fold': fold, 'rmse': rmse, 'r2': r2})
        models.append(model)
        
        print(f"     Fold {fold+1}: RMSE={rmse:.4f}, RÂ²={r2:.4f}")
    
    # CV ê²°ê³¼ ì •ë¦¬
    avg_rmse = np.mean([s['rmse'] for s in cv_scores])
    avg_r2 = np.mean([s['r2'] for s in cv_scores])
    std_rmse = np.std([s['rmse'] for s in cv_scores])
    std_r2 = np.std([s['r2'] for s in cv_scores])
    
    return {
        'models': models,
        'cv_scores': cv_scores,
        'avg_rmse': avg_rmse,
        'std_rmse': std_rmse,
        'avg_r2': avg_r2,
        'std_r2': std_r2
    }

def train_xgboost_multi_target(embedding_path: str, output_dir: str = "./xgb_results"):
    """
    ViT ì„ë² ë”©ì„ ì‚¬ìš©í•´ ë‹¤ì¤‘ íƒ€ê²Ÿ XGBoost í•™ìŠµ
    """
    print("=== ViT â†’ XGBoost í•™ìŠµ ì‹œì‘ ===\n")
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    os.makedirs(output_dir, exist_ok=True)
    
    # 1. ì„ë² ë”© ë¡œë“œ
    df, feature_cols, label_cols = load_embeddings(embedding_path)
    
    # 2. ë°ì´í„° ì¤€ë¹„
    X = df[feature_cols].values
    sample_ids = df['sample_id'].values
    
    # ê·¸ë£¹ ì •ë³´ (ì´ë ¥ë²ˆí˜¸ ì¶”ì¶œ)
    groups = np.array([sid.split('_')[0] for sid in sample_ids])
    
    print(f"\nğŸ“Š ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ:")
    print(f"   ìƒ˜í”Œ ìˆ˜: {len(X)}")
    print(f"   í”¼ì²˜ ì°¨ì›: {X.shape[1]}")
    print(f"   ê³ ìœ  ê·¸ë£¹ ìˆ˜: {len(np.unique(groups))}")
    
    # 3. XGBoost í•˜ì´í¼íŒŒë¼ë¯¸í„°
    xgb_params = {
        'objective': 'reg:squarederror',
        'max_depth': 6,
        'learning_rate': 0.1,
        'subsample': 0.8,
        'colsample_bytree': 0.8,
        'random_state': 2025,
        'n_estimators': 100
    }
    
    # 4. ê° íƒ€ê²Ÿë³„ë¡œ í•™ìŠµ
    all_results = {}
    
    for label_col in label_cols:
        target_name = label_col.replace('y_', '')
        print(f"\nğŸ¯ íƒ€ê²Ÿ: {target_name}")
        
        y = df[label_col].values
        
        # ê²°ì¸¡ì¹˜ ì²˜ë¦¬
        valid_mask = ~np.isnan(y)
        if not valid_mask.all():
            print(f"   ê²°ì¸¡ì¹˜ {np.sum(~valid_mask)}ê°œ ì œê±°")
            X_clean = X[valid_mask]
            y_clean = y[valid_mask]
            groups_clean = groups[valid_mask]
        else:
            X_clean, y_clean, groups_clean = X, y, groups
        
        # XGBoost í•™ìŠµ
        result = train_xgboost_single_target(X_clean, y_clean, groups_clean, xgb_params)
        all_results[target_name] = result
        
        print(f"   í‰ê·  RMSE: {result['avg_rmse']:.4f} Â± {result['std_rmse']:.4f}")
        print(f"   í‰ê·  RÂ²: {result['avg_r2']:.4f} Â± {result['std_r2']:.4f}")
        
        # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì €ì¥
        best_fold = np.argmin([s['rmse'] for s in result['cv_scores']])
        best_model = result['models'][best_fold]
        
        model_path = os.path.join(output_dir, f"xgb_{target_name}.pkl")
        joblib.dump(best_model, model_path)
        print(f"   ëª¨ë¸ ì €ì¥: {model_path}")
    
    # 5. ì „ì²´ ê²°ê³¼ ì •ë¦¬
    summary = {
        'embedding_source': embedding_path,
        'feature_dim': X.shape[1],
        'n_samples': len(X),
        'n_groups': len(np.unique(groups)),
        'xgb_params': xgb_params,
        'results': {}
    }
    
    print(f"\n=== ì „ì²´ ê²°ê³¼ ìš”ì•½ ===")
    for target_name, result in all_results.items():
        summary['results'][target_name] = {
            'avg_rmse': float(result['avg_rmse']),
            'std_rmse': float(result['std_rmse']),
            'avg_r2': float(result['avg_r2']),
            'std_r2': float(result['std_r2'])
        }
        
        print(f"{target_name:>15}: RMSE={result['avg_rmse']:.4f}Â±{result['std_rmse']:.4f}, RÂ²={result['avg_r2']:.4f}Â±{result['std_r2']:.4f}")
    
    # ê²°ê³¼ ì €ì¥
    summary_path = os.path.join(output_dir, "xgb_summary.json")
    with open(summary_path, 'w', encoding='utf-8') as f:
        json.dump(summary, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ’¾ ê²°ê³¼ ì €ì¥: {summary_path}")
    print(f"ğŸ‰ XGBoost í•™ìŠµ ì™„ë£Œ!")
    
    return all_results, summary

def predict_with_xgboost(embedding_path: str, model_dir: str = "./xgb_results", 
                        output_path: str = "./xgb_predictions.csv"):
    """
    í•™ìŠµëœ XGBoost ëª¨ë¸ë¡œ ì˜ˆì¸¡
    """
    print("=== XGBoost ì˜ˆì¸¡ ì‹œì‘ ===\n")
    
    # ì„ë² ë”© ë¡œë“œ
    df, feature_cols, label_cols = load_embeddings(embedding_path)
    X = df[feature_cols].values
    sample_ids = df['sample_id'].values
    
    predictions = {'sample_id': sample_ids}
    
    # ê° íƒ€ê²Ÿë³„ ì˜ˆì¸¡
    for label_col in label_cols:
        target_name = label_col.replace('y_', '')
        model_path = os.path.join(model_dir, f"xgb_{target_name}.pkl")
        
        if os.path.exists(model_path):
            model = joblib.load(model_path)
            pred = model.predict(X)
            predictions[f"pred_{target_name}"] = pred
            
            # ì‹¤ì œ ë¼ë²¨ë„ í¬í•¨
            if label_col in df.columns:
                predictions[f"true_{target_name}"] = df[label_col].values
            
            print(f"âœ… {target_name} ì˜ˆì¸¡ ì™„ë£Œ")
        else:
            print(f"âŒ ëª¨ë¸ ì—†ìŒ: {model_path}")
    
    # ê²°ê³¼ ì €ì¥
    pred_df = pd.DataFrame(predictions)
    pred_df.to_csv(output_path, index=False)
    
    print(f"\nğŸ’¾ ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥: {output_path}")
    return pred_df

if __name__ == "__main__":
    # ì‚¬ìš© ì˜ˆì‹œ
    embedding_file = "./runs_vit_light/test_embeddings.parquet"
    
    if os.path.exists(embedding_file):
        print("ğŸš€ ViT ì„ë² ë”©ì„ XGBoostë¡œ í•™ìŠµí•©ë‹ˆë‹¤...")
        results, summary = train_xgboost_multi_target(embedding_file)
        
        print("\nğŸ”® ì˜ˆì¸¡ë„ ì‹¤í–‰í•©ë‹ˆë‹¤...")
        predictions = predict_with_xgboost(embedding_file)
        
    else:
        print(f"âŒ ì„ë² ë”© íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {embedding_file}")
        print("ë¨¼ì € ViT í•™ìŠµì„ ì™„ë£Œí•˜ì„¸ìš”: python train_vit_light.py --config config_vit_light_fixed.yaml")